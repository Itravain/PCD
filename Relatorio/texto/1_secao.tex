A crescente demanda por desempenho computacional tem impulsionado o desenvolvimento de técnicas de paralelização, que permitem a execução simultânea de múltiplas tarefas, otimizando o uso de recursos e reduzindo o tempo de processamento. A computação paralela é fundamental para resolver problemas complexos e de grande escala, como simulações científicas, análise de big data e aprendizado de máquina.

\par OpenMP é um acrônimo para Open Multi-Processing, que é uma API para desenvolvimento de programas em arquiteturas de memória compartilhada. Foi desenvolvido em 1997 por um consórcio liderado pela Intel e pelo Departamento de Energia dos Estados Unidos. O seu principal objetivo é facilitar a paralelização de programas em linguagens como C, C++ e Fortran. \cite{cornell_openmp_history}.
